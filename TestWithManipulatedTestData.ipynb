{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting manuel_seed to have consistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fc6ce36030>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test dataset which we have created in ImagepredictionCNN.ipynb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kirta\\AppData\\Local\\Temp\\ipykernel_3772\\371614586.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data  = torch.load('test_dataset.pth')\n"
     ]
    }
   ],
   "source": [
    "test_data  = torch.load('test_dataset.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have initial scores, I only changed the size of images and convert them to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.dataset.transform = test_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data by using Pytorch.DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we used when training cnn, we need to create the class again. But we only need its structure, we will not train again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 20, 3), # 128 - 3 + 1 = 126, After each convolution, the size of the image is reduced by 2 pixels\n",
    "            nn.BatchNorm2d(20), # Normalize the output of the convolutional layer\n",
    "            nn.ReLU(), # Activation function\n",
    "            nn.Conv2d(20, 40, 3), # 126 - 3 + 1 = 124, Again the size of image is reduced by 2 pixels\n",
    "            nn.BatchNorm2d(40), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # 124 / 2 = 62, Max pooling reduces the size of the image by half\n",
    "            nn.Conv2d(40, 80, 3), # 62 - 3 + 1 = 60\n",
    "            nn.BatchNorm2d(80),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(80, 160, 3), # 60 - 3 + 1 = 58\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2) # 58 / 2 = 29\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(160, 200), # We gave 160 as input because adaptive_avg_pool2d will return 160 features\n",
    "            nn.ReLU(), # Activation function\n",
    "            nn.Dropout(0.5), # Randomly drop 50% of the connections, which helps to prevent overfitting\n",
    "            nn.Linear(200, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(100, 10) # Because we have 10 classes, the last layer has 10 neurons\n",
    "        )\n",
    "    # Forward pass\n",
    "    def forward(self, x):\n",
    "        x = self.features(x) # Extract features\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1)) # Average pooling, the size of the image is reduced to 1x1\n",
    "        x = torch.flatten(x, 1) # Flatten the output of the convolutional layers\n",
    "        x = self.classifier(x) # Classify the image\n",
    "        return x # Return the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If cuda available, set device to cuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning our model to available device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to go further training, we need to have criterion and optimizer again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using Pytorch.load() function, we can load pretrained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kirta\\AppData\\Local\\Temp\\ipykernel_3772\\1480547802.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"cnn_trained.pth\", map_location='cuda')\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"cnn_trained.pth\", map_location='cuda')\n",
    "cnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "start_epoch = checkpoint['epoch'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like I used in training, I created same function here. The comments and functions almost same to previous one. The only difference it takes dataloader as parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model, test_dataloader):\n",
    "    # Get class labels\n",
    "    classes = list(test_data.dataset.class_to_idx.keys())\n",
    "    # Initialize the correct and total predictions\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "    # Prepare to count predictions for each class\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "    # Because we are not evaluating the model, we need to use torch.no_grad() function.\n",
    "    with torch.no_grad():\n",
    "        # Get the data from the test dataloader\n",
    "        for data in test_dataloader:\n",
    "            # Get images and labels and assign it to device\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Predict the images\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Get the maximum value of the predictions\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            # Collect the correct predictions for each class\n",
    "            total_prediction += labels.size(0)\n",
    "            correct_prediction += (predictions == labels).sum().item()\n",
    "\n",
    "            # Assign the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label.item()]] += 1\n",
    "                total_pred[classes[label.item()]] += 1\n",
    "\n",
    "    # Print the accuracy of cnn.\n",
    "    print(f'Accuracy of the network on the {total_prediction} test images: {100 * correct_prediction / total_prediction:.2f} %')\n",
    "    \n",
    "    # Print accuracy for each class\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see whether our model loaded correctly, I run get_scores function again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1300 test images: 77.23 %\n",
      "Accuracy for class: collie is 76.9 %\n",
      "Accuracy for class: dolphin is 93.1 %\n",
      "Accuracy for class: elephant is 76.2 %\n",
      "Accuracy for class: fox   is 60.0 %\n",
      "Accuracy for class: giant+panda is 89.2 %\n",
      "Accuracy for class: moose is 77.7 %\n",
      "Accuracy for class: polar+bear is 93.1 %\n",
      "Accuracy for class: rabbit is 56.9 %\n",
      "Accuracy for class: sheep is 80.0 %\n",
      "Accuracy for class: squirrel is 69.2 %\n"
     ]
    }
   ],
   "source": [
    "get_scores(cnn, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this is our model trained model score with no further image manipulation. Let's manipulate test_images to see how our model performing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first test is by decreasing contrast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrease_contrast = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ColorJitter(brightness=1, contrast=0.3, saturation=1, hue=0.5),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kirta\\AppData\\Local\\Temp\\ipykernel_3772\\480002507.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  contrast_test = torch.load('test_dataset.pth')\n"
     ]
    }
   ],
   "source": [
    "contrast_test = torch.load('test_dataset.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_test.dataset.transform = decrease_contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_dataloader = DataLoader(contrast_test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1300 test images: 33.00 %\n",
      "Accuracy for class: collie is 28.5 %\n",
      "Accuracy for class: dolphin is 23.8 %\n",
      "Accuracy for class: elephant is 33.1 %\n",
      "Accuracy for class: fox   is 20.0 %\n",
      "Accuracy for class: giant+panda is 36.2 %\n",
      "Accuracy for class: moose is 40.0 %\n",
      "Accuracy for class: polar+bear is 58.5 %\n",
      "Accuracy for class: rabbit is 32.3 %\n",
      "Accuracy for class: sheep is 32.3 %\n",
      "Accuracy for class: squirrel is 25.4 %\n"
     ]
    }
   ],
   "source": [
    "get_scores(cnn, contrast_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, decreasing contrast significantly dropped our model performance. Let's change brightness this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrease_brightness = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=1, saturation=1, hue=0.5),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kirta\\AppData\\Local\\Temp\\ipykernel_3772\\1982252977.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  brightness_test = torch.load('test_dataset.pth')\n"
     ]
    }
   ],
   "source": [
    "brightness_test = torch.load('test_dataset.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness_test.dataset.transform = decrease_brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness_dataloader = DataLoader(brightness_test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1300 test images: 29.77 %\n",
      "Accuracy for class: collie is 34.6 %\n",
      "Accuracy for class: dolphin is 23.1 %\n",
      "Accuracy for class: elephant is 30.8 %\n",
      "Accuracy for class: fox   is 18.5 %\n",
      "Accuracy for class: giant+panda is 27.7 %\n",
      "Accuracy for class: moose is 40.0 %\n",
      "Accuracy for class: polar+bear is 44.6 %\n",
      "Accuracy for class: rabbit is 28.5 %\n",
      "Accuracy for class: sheep is 27.7 %\n",
      "Accuracy for class: squirrel is 22.3 %\n"
     ]
    }
   ],
   "source": [
    "get_scores(cnn, brightness_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see again, our model performance decrease dramatically. Let's run for lower saturation this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrease_saturation = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ColorJitter(brightness=1, contrast=1, saturation=0.3, hue=0.5),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kirta\\AppData\\Local\\Temp\\ipykernel_3772\\552764555.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saturation_test = torch.load('test_dataset.pth')\n"
     ]
    }
   ],
   "source": [
    "saturation_test = torch.load('test_dataset.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturation_test.dataset.transform = decrease_saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturation_dataloader = DataLoader(saturation_test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1300 test images: 26.38 %\n",
      "Accuracy for class: collie is 29.2 %\n",
      "Accuracy for class: dolphin is 22.3 %\n",
      "Accuracy for class: elephant is 23.8 %\n",
      "Accuracy for class: fox   is 16.9 %\n",
      "Accuracy for class: giant+panda is 16.2 %\n",
      "Accuracy for class: moose is 33.8 %\n",
      "Accuracy for class: polar+bear is 52.3 %\n",
      "Accuracy for class: rabbit is 32.3 %\n",
      "Accuracy for class: sheep is 20.0 %\n",
      "Accuracy for class: squirrel is 16.9 %\n"
     ]
    }
   ],
   "source": [
    "get_scores(cnn, saturation_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in all three case, decreasing image light properties gives significant drop in model performance. Let's run tests for increasing extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase_contrast = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ColorJitter(brightness=1, contrast=3, saturation=1, hue=0.5),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kirta\\AppData\\Local\\Temp\\ipykernel_3772\\2444280604.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  increase_contrast_test = torch.load('test_dataset.pth')\n"
     ]
    }
   ],
   "source": [
    "increase_contrast_test = torch.load('test_dataset.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase_contrast_test.dataset.transform = increase_contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase_contrast_dataloader = DataLoader(increase_contrast_test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1300 test images: 21.38 %\n",
      "Accuracy for class: collie is 21.5 %\n",
      "Accuracy for class: dolphin is 21.5 %\n",
      "Accuracy for class: elephant is 20.0 %\n",
      "Accuracy for class: fox   is 12.3 %\n",
      "Accuracy for class: giant+panda is 15.4 %\n",
      "Accuracy for class: moose is 21.5 %\n",
      "Accuracy for class: polar+bear is 42.3 %\n",
      "Accuracy for class: rabbit is 19.2 %\n",
      "Accuracy for class: sheep is 20.8 %\n",
      "Accuracy for class: squirrel is 19.2 %\n"
     ]
    }
   ],
   "source": [
    "get_scores(cnn, increase_contrast_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make conclusion, our model has poor performance for different light types. Which indicates our model may overfitted to train dataset. To get better performance even in different light situations, we need to train model with different light source types, create new data augmentation properties etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Consistency Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I am defining function to apply gray_world algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gray_world(image):\n",
    "    image = image * 255.0  # Convert to [0, 255] range\n",
    "\n",
    "    # Calculate the average color per channel (B, G, R)\n",
    "    avg_b, avg_g, avg_r = image[0].mean(), image[1].mean(), image[2].mean()\n",
    "    \n",
    "    # Compute the gray value and scaling factors\n",
    "    gray_value = (avg_b + avg_g + avg_r) / 3\n",
    "    scaling_factors = torch.tensor([gray_value / avg_b, gray_value / avg_g, gray_value / avg_r])\n",
    "    \n",
    "    # Apply scaling factors to each channel (B, G, R)\n",
    "    corrected_image = image * scaling_factors.view(3, 1, 1)  # Broadcast scaling factors\n",
    "\n",
    "    # Ensure the result stays within the valid range and return it\n",
    "    corrected_image = torch.clamp(corrected_image, 0, 255) / 255.0\n",
    "    return corrected_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After function definition, I created class, which help us to run the function inside Pytorch.transforms.Compose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrayWorldTransform:\n",
    "    def __call__(self, image):\n",
    "        return apply_gray_world(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all setup, we are good to go to apply gray_world algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    GrayWorldTransform()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how algorithm works, I apply the transformation to dataset which we are already have: increase_contrast_test. In this dataset, we changed the contrast and got 21% correct guess. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase_contrast_test.dataset.transform = transform # Apply the Gray World transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase_contrast_dataloader = DataLoader(increase_contrast_test, batch_size=64, shuffle=True) # Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1300 test images: 67.69 %\n",
      "Accuracy for class: collie is 72.3 %\n",
      "Accuracy for class: dolphin is 76.9 %\n",
      "Accuracy for class: elephant is 66.9 %\n",
      "Accuracy for class: fox   is 44.6 %\n",
      "Accuracy for class: giant+panda is 80.8 %\n",
      "Accuracy for class: moose is 70.8 %\n",
      "Accuracy for class: polar+bear is 90.0 %\n",
      "Accuracy for class: rabbit is 47.7 %\n",
      "Accuracy for class: sheep is 67.7 %\n",
      "Accuracy for class: squirrel is 59.2 %\n"
     ]
    }
   ],
   "source": [
    "get_scores(cnn, increase_contrast_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see with results, our model performed pretty good again. This indicates that our model getting significant gain by using Gray World algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how our scores changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_test.dataset.transform = transform # Apply gray world algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_dataloader = DataLoader(contrast_test, batch_size=64, shuffle=True) # Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1300 test images: 66.92 %\n",
      "Accuracy for class: collie is 73.8 %\n",
      "Accuracy for class: dolphin is 76.9 %\n",
      "Accuracy for class: elephant is 67.7 %\n",
      "Accuracy for class: fox   is 44.6 %\n",
      "Accuracy for class: giant+panda is 80.0 %\n",
      "Accuracy for class: moose is 68.5 %\n",
      "Accuracy for class: polar+bear is 86.2 %\n",
      "Accuracy for class: rabbit is 43.8 %\n",
      "Accuracy for class: sheep is 66.2 %\n",
      "Accuracy for class: squirrel is 61.5 %\n"
     ]
    }
   ],
   "source": [
    "get_scores(cnn, contrast_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the result are increased significantly increased again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I want to apply gray world algorithm to our original dataset. To see is there any increase in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.dataset.transform = transform # Apply gray world algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True) # Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1300 test images: 69.08 %\n",
      "Accuracy for class: collie is 76.9 %\n",
      "Accuracy for class: dolphin is 76.9 %\n",
      "Accuracy for class: elephant is 71.5 %\n",
      "Accuracy for class: fox   is 45.4 %\n",
      "Accuracy for class: giant+panda is 80.8 %\n",
      "Accuracy for class: moose is 70.8 %\n",
      "Accuracy for class: polar+bear is 87.7 %\n",
      "Accuracy for class: rabbit is 49.2 %\n",
      "Accuracy for class: sheep is 65.4 %\n",
      "Accuracy for class: squirrel is 66.2 %\n"
     ]
    }
   ],
   "source": [
    "get_scores(cnn, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model's initial score was better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To conclusion, our model has good prediction score if the images are good. If the images are not like wanted style, we can apply gray world algorithm and get good predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
